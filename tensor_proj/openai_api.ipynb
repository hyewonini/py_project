{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efff65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#print('key:', OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7e59371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='ì–´ë²¤ì ¸ìŠ¤ ì‹œë¦¬ì¦ˆì˜ í† ë¥´ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66529e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í† ë¥´ëŠ” ì•„ìŠ¤ê°€ë¥´ë“œì˜ ì²œë‘¥ì˜ ì‹ ìœ¼ë¡œ, ë§‰ê°•í•œ í˜ê³¼ ë¬ ë‹ˆë¥´ ë§ì¹˜ë¥¼ ì‚¬ìš©í•´ ì–´ë²¤ì ¸ìŠ¤ì˜ í•µì‹¬ ë©¤ë²„ë¡œ í™œì•½í•œë‹¤.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d06a30cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í† ë¥´ëŠ” ì•„ìŠ¤ê°€ë¥´ë“œì˜ ì²œë‘¥ì˜ ì‹ ìœ¼ë¡œ, ê°•ë ¥í•œ í˜ê³¼ ë¬ ë‹ˆë¥´ ë§ì¹˜ë¥¼ ì•ì„¸ì›Œ ì–´ë²¤ì ¸ìŠ¤ íŒ€ì˜ í•µì‹¬ ì „ì‚¬ ì—­í• ì„ í•œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    instructions='ë‹¹ì‹ ì€ ì˜í™”í‰ë¡ ê°€ì•¼',\n",
    "    input=\"ì–´ë²¤ì ¸ìŠ¤ ì‹œë¦¬ì¦ˆì˜ í† ë¥´ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ëª…í•´ì¤˜\"\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d452fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²Œì„ ì–˜ê¸°ë¼ë‹ˆ ë„ˆë¬´ ì¢‹ì•„! ğŸ˜Š ì–´ë–¤ ì¥ë¥´ë¥¼ ì¢‹ì•„í•´? ê°€ë²¼ìš´ ê²Œì„, í˜‘ë™/íŒŒí‹° ê²Œì„, ê¹Šì´ ìˆëŠ” ì „ëµ ê²Œì„, RPG, ì•„ë‹ˆë©´ ì•¡ì…˜ ê²Œì„ ë“±ë“±â€¦ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ë‚˜ ìƒí™©ì„ ì•Œë ¤ì£¼ë©´ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆì–´!\n",
      "\n",
      "í˜¹ì‹œ ì˜¤ëŠ˜ í˜¼ìì„œ í•  ìƒê°ì´ì•¼? ì¹œêµ¬ë“¤ì´ë‚˜ ê°€ì¡±ì´ë‘ ê°™ì´ í•  ê³„íšì´ì•¼?  \n",
      "í”Œë«í¼(PC, ì½˜ì†”, ëª¨ë°”ì¼ ë“±)ë„ ë§í•´ì£¼ë©´ ë” ë”± ë§ëŠ” ê²Œì„ë“¤ì„ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆì–´!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role' : 'developer',\n",
    "            'content' : 'ê²Œì„ì— ëŒ€í•œ ì´ì•¼ê¸° í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•´'\n",
    "        },\n",
    "        {\n",
    "            'role' : 'user', \n",
    "            'content' : 'ì˜¤ëŠ˜ì€ ë¬´ìŠ¨ ê²Œì„ì„ í• ê¹Œ?'\n",
    "        }]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a046fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages=[\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'ì–´ë²¤ì ¸ìŠ¤ ì‹œë¦¬ì¦ˆì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    "        }]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09640beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì–´ë²¤ì ¸ìŠ¤ ì‹œë¦¬ì¦ˆëŠ” ë‹¤ì–‘í•œ ìŠˆí¼íˆì–´ë¡œë“¤ì´ í˜ì„ í•©ì³ ì§€êµ¬ì™€ ìš°ì£¼ë¥¼ ìœ„í˜‘í•˜ëŠ” ê°•ë ¥í•œ ì•…ë‹¹ì— ë§ì„œ ì‹¸ìš°ëŠ” ë§ˆë¸” ì‹œë„¤ë§ˆí‹± ìœ ë‹ˆë²„ìŠ¤(MCU)ì˜ ëŒ€í‘œì ì¸ ì˜í™” ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(completion.choices[0])\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace0ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ã…”ìˆ‘! ğŸ˜€ ë°˜ê°€ì›Œìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”? ê¶ê¸ˆí•œ ê±° ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "user_input = input(\"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” : \")\n",
    "prompt = input(\"í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” : \")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role' : 'developer',\n",
    "            \"content\": prompt\n",
    "    \n",
    "        },\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            \"content\" : user_input \n",
    "            \n",
    "        }]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963476f",
   "metadata": {},
   "source": [
    "File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54e51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "    # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "    )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "            file=file_content,\n",
    "            purpose=\"assistants\"\n",
    ")\n",
    "    print(result.id)\n",
    "    return result.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08dafb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-XqL3GVqVu6rY7RLRiKSt1m\n"
     ]
    }
   ],
   "source": [
    "file_id = create_file(client, './howto-sockets.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5478e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_685cd1a664388191a24c4b7af5652380\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name='knowledge_base'\n",
    ")\n",
    "\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3274ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-XqL3GVqVu6rY7RLRiKSt1m', created_at=1750913447, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cd1a664388191a24c4b7af5652380', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9852ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-XqL3GVqVu6rY7RLRiKSt1m', created_at=1750913447, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cd1a664388191a24c4b7af5652380', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-XqL3GVqVu6rY7RLRiKSt1m', last_id='file-XqL3GVqVu6rY7RLRiKSt1m')\n"
     ]
    }
   ],
   "source": [
    "result_list = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc4e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_685cd1a78ae8819999c5af6335e56fbe0e6a97f33172732f', created_at=1750913447.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_685cd1a816ec8199a1f91f26dee5c7cd0e6a97f33172732f', content=[ResponseOutputText(annotations=[], text=\"íŒŒì´ì¬ì—ì„œ ì†Œì¼“(socket)ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\\n\\n1. ì†Œì¼“ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸  \\në¨¼ì €, íŒŒì´ì¬ ë‚´ì¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ `socket`ì„ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤.\\n```python\\nimport socket\\n```\\n\\n2. ì†Œì¼“ ê°ì²´ ìƒì„±  \\në‹¤ìŒê³¼ ê°™ì´ ì†Œì¼“ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\\n```python\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n```\\nì—¬ê¸°ì„œ `AF_INET`ì€ IPv4ë¥¼, `SOCK_STREAM`ì€ TCP íƒ€ì…ì˜ ì†Œì¼“ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\\n\\n3. ì„œë²„/í´ë¼ì´ì–¸íŠ¸ ì—­í• ì— ë”°ë¼ ë¶„ê¸°  \\n- **ì„œë²„** ìš© ì†Œì¼“ì˜ ê²½ìš°\\n  - ì£¼ì†Œ, í¬íŠ¸ì— ë°”ì¸ë”©(bind):  \\n    ```python\\n    s.bind(('localhost', 12345))\\n    ```\\n  - ì—°ê²° ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜(listen):  \\n    ```python\\n    s.listen(1)\\n    ```\\n  - ì—°ê²° ìš”ì²­ì„ ìˆ˜ë½(accept):  \\n    ```python\\n    conn, addr = s.accept()\\n    ```\\n\\n- **í´ë¼ì´ì–¸íŠ¸** ìš© ì†Œì¼“ì˜ ê²½ìš°  \\n  - ì„œë²„ì— ì—°ê²°(connect):  \\n    ```python\\n    s.connect(('localhost', 12345))\\n    ```\\n\\n4. ë°ì´í„° ì†¡ìˆ˜ì‹   \\n- ì†¡ì‹ (send):  \\n  ```python\\n  s.sendall(b'Hello, world')\\n  ```\\n- ìˆ˜ì‹ (recv):  \\n  ```python\\n  data = s.recv(1024)\\n  ```\\n\\n5. ì†Œì¼“ ì¢…ë£Œ  \\n```python\\ns.close()\\n```\\n\\n---\\n\\nê°„ë‹¨ ì˜ˆì‹œ (ì„œë²„):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.bind(('localhost', 12345))\\ns.listen(1)\\nconn, addr = s.accept()\\nprint('Connected by', addr)\\ndata = conn.recv(1024)\\nconn.sendall(data)\\nconn.close()\\ns.close()\\n```\\n\\nê°„ë‹¨ ì˜ˆì‹œ (í´ë¼ì´ì–¸íŠ¸):\\n```python\\nimport socket\\n\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\ns.connect(('localhost', 12345))\\ns.sendall(b'Hello, world')\\ndata = s.recv(1024)\\nprint('Received', repr(data))\\ns.close()\\n```\\n\\nê¶ê¸ˆí•œ ë¶€ë¶„ì´ë‚˜ ë” êµ¬ì²´ì ì¸ ì˜ˆì œê°€ í•„ìš”í•˜ë©´ ì¶”ê°€ë¡œ ë¬¼ì–´ë³´ì„¸ìš”!\", type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_685cd1a664388191a24c4b7af5652380'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=812, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=501, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1313), user=None, max_tool_calls=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='íŒŒì´ì¬ ì½”ë“œë¡œ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜',\n",
    "    tools=[{\n",
    "        \"type\" : \"file_search\",\n",
    "        \"vector_store_ids\" : [vector_store.id]\n",
    "    }],\n",
    "    tool_choice='auto'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d35266",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
